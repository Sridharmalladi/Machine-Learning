{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4e15a9-0124-4673-b790-9f1c4725ebd6",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cad208-92fc-4299-8206-c0b5dbad5a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc3913-6cfd-48ac-8f7e-89f326985a3a",
   "metadata": {},
   "source": [
    "# Loading the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf1bf7c-894b-4aa6-abdc-a580facf5354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('spam.csv', header=None, encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d885b4e-7e6f-4381-80f3-b8b051f2ddfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5573 entries, 0 to 5572\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5573 non-null   object\n",
      " 1   1       5573 non-null   object\n",
      " 2   2       50 non-null     object\n",
      " 3   3       12 non-null     object\n",
      " 4   4       6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n",
      "None\n",
      "      0                                                  1    2    3    4\n",
      "0    v1                                            message  NaN  NaN  NaN\n",
      "1   ham  Go until jurong point, crazy.. Available only ...  NaN  NaN  NaN\n",
      "2   ham                      Ok lar... Joking wif u oni...  NaN  NaN  NaN\n",
      "3  spam  Free entry in 2 a wkly comp to win FA Cup fina...  NaN  NaN  NaN\n",
      "4   ham  U dun say so early hor... U c already then say...  NaN  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de919b7-532d-4b51-aa44-f90dee12f8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ham     4825\n",
      "spam     747\n",
      "v1         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check class distribution\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854079a9-bb57-412d-baff-8b34881c6209",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d499da56-addd-47f8-b728-b24d8733d667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 1 0 0 1 0 0 1]\n",
      "Index([0, 1, 2, 3, 4], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convert class labels to binary values, 0 = ham and 1 = spam\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "\n",
    "print(Y[:10])\n",
    "\n",
    "# Print the column names to find the correct column name for text messages\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccde2f6-8316-4d89-9166-b34785f8552b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                              message\n",
      "1    Go until jurong point, crazy.. Available only ...\n",
      "2                        Ok lar... Joking wif u oni...\n",
      "3    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "4    U dun say so early hor... U c already then say...\n",
      "5    Nah I don't think he goes to usf, he lives aro...\n",
      "6    FreeMsg Hey there darling it's been 3 week's n...\n",
      "7    Even my brother is not like to speak with me. ...\n",
      "8    As per your request 'Melle Melle (Oru Minnamin...\n",
      "9    WINNER!! As a valued network customer you have...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_messages = df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1799b9-8d9a-4d21-a36f-c3694c05098b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
    "\n",
    "#Replacing email addresses with 'email'\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "#Replacing URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "#Replacing money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "#Replacing 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    \n",
    "#Replacing numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b05cfa5-028a-4f55-8660-59ec991ab4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "711c0c71-fa40-4fb9-b763-679c9107175a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                 message\n",
      "1       go until jurong point, crazy.. available only ...\n",
      "2                           ok lar... joking wif u oni...\n",
      "3       free entry in 2 a wkly comp to win fa cup fina...\n",
      "4       u dun say so early hor... u c already then say...\n",
      "                              ...                        \n",
      "5568    this is the 2nd time we have tried 2 contact u...\n",
      "5569                will ì_ b going to esplanade fr home?\n",
      "5570    pity, * was in mood for that. so...any other s...\n",
      "5571    the guy did some bitching but i acted like i'd...\n",
      "5572                           rofl. its true to its name\n",
      "Name: 1, Length: 5573, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# change words to lower case - Hello, HELLO, hello are all the same word\n",
    "processed = processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ef8dfd-63bd-40cc-8afb-f1f3394719fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383ada49-8a8a-48f8-a0c9-b70a9895164a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove word stems using a Porter stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007431b-2f92-4920-944b-0a91d99f3dd1",
   "metadata": {},
   "source": [
    "# Generating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f073ba9-122c-4cbb-96ff-5ffb9f238c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# create bag-of-words\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b81fe92-a8d5-4caa-a302-7a5c1580cfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 8951\n",
      "Most common words: [('.', 4713), (',', 1872), ('?', 1541), ('!', 1381), ('...', 1131), ('u', 1121), ('&', 916), (';', 764), (':', 717), ('i', 695), ('..', 681), ('call', 642), (\"'\", 533), (')', 494), ('2', 474)]\n"
     ]
    }
   ],
   "source": [
    "# print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "701c2197-7d9f-4a40-988c-219b04b29476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aed00b65-7144-4d07-9af3-0d0b16957f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messag\n"
     ]
    }
   ],
   "source": [
    "# The find_features function will determine which of the 1500 word features are contained in the review\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Example: Find features in the first processed message\n",
    "features = find_features(processed[0])\n",
    "\n",
    "# Print words that are features\n",
    "for key, value in features.items():\n",
    "    if value:\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be70575-00ba-4c0d-a66c-7c8b00fd9a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Now lets do it for all the messages\n",
    "messages = zip(processed, Y)\n",
    "\n",
    "# Define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)  # Use np.random.seed(seed) to set the random seed\n",
    "\n",
    "\n",
    "# call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41249d5-aef3-48cb-af6c-3aafb59645ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can split the featuresets into training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9707d36-b796-4482-bc4d-8540bcd99401",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1394\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f76496-8dd5-4b1e-bddd-793723c5eb90",
   "metadata": {},
   "source": [
    "# Scikit-Learn Classifiers with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45e2246d-e31a-48ac-b439-b355d3eb617b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 98.49354375896701\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272bc9e-a738-4d4e-b53f-58bba1c0b3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a87f1a91-40d7-4661-9776-93991cf6f774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 92.47%\n",
      "Decision Tree Accuracy: 96.05%\n",
      "Random Forest Accuracy: 97.99%\n",
      "Logistic Regression Accuracy: 98.42%\n",
      "SGD Classifier Accuracy: 97.99%\n",
      "Naive Bayes Accuracy: 98.35%\n",
      "SVM Linear Accuracy: 98.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from nltk.classify import SklearnClassifier  # Import SklearnClassifier\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter=100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))  # Use list() to convert the zip to a list\n",
    "\n",
    "# Assuming you have your 'training' and 'testing' datasets prepared correctly\n",
    "# You should have something like 'training' as a list of tuples: [(featureset1, label1), (featureset2, label2), ...]\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing) * 100\n",
    "    print(\"{} Accuracy: {:.2f}%\".format(name, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17fdfefb-f6f1-4b5c-8a6c-3acf1dae2eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk  # Import NLTK or any other required libraries\n",
    "from nltk.classify import NaiveBayesClassifier  # Import the classifier you're using\n",
    "\n",
    "# Training your ensemble classifier with the training data\n",
    "nltk_ensemble = NaiveBayesClassifier.train(training)\n",
    "\n",
    "# Making class label predictions for the testing set\n",
    "txt_features, labels = zip(*testing)\n",
    "prediction = nltk_ensemble.classify_many(txt_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f621b845-b8ff-4201-b3e8-4939e407b25b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1214\n",
      "           1       0.98      0.91      0.94       180\n",
      "\n",
      "    accuracy                           0.99      1394\n",
      "   macro avg       0.98      0.95      0.97      1394\n",
      "weighted avg       0.99      0.99      0.99      1394\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>16</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1210    4\n",
       "       spam        16  164"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and a classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0f4e2-2449-4745-b031-3be073c618c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
